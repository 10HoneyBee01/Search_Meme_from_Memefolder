{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top memes based on text query:\n",
      "Image: 14 - 1(2).png, Similarity: 0.2910\n",
      "Image: 912488_170x100.png, Similarity: 0.2811\n",
      "Image: miVWSLVYCZoeUs6hoaSGXgbq_tEqpOiHMi7WnOQSEcdJ3npMk-djfRe4qKv4etX2aikXt9U64xzDrUdEr9IqXH_0JiPCuITESiBo2GMf=w346-h490.jpg, Similarity: 0.2786\n",
      "Image: MvOXQLkhcWM2ytqq27txg_U9JBUeQsDlGJX8MnarmIDB9y4XHuIzDkdtf9tOY52_zOehyXZm3Wjt5pSjy8eG74nOOlgM-phxFULh8zWlVaUp_H99=w346-h468.jpg, Similarity: 0.2744\n",
      "Image: images-17.jpeg, Similarity: 0.2737\n"
     ]
    }
   ],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Initialize CLIP model and processor\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "# Function to extract text features from the query text\n",
    "def extract_text_features(query_text):\n",
    "    # Preprocess the text input\n",
    "    inputs = processor(text=query_text, return_tensors=\"pt\", padding=True)\n",
    "    \n",
    "    # Get the text features from CLIP model\n",
    "    outputs = model.get_text_features(**inputs)  # Use get_text_features to get the text features\n",
    "    text_features = outputs  # Text features\n",
    "    \n",
    "    return text_features\n",
    "\n",
    "# Function to extract image features from meme images\n",
    "def extract_image_features(meme_image, query_text):\n",
    "    # Process the meme image along with the query text to get image features\n",
    "    inputs = processor(text=query_text, images=meme_image, return_tensors=\"pt\", padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    meme_image_features = outputs.image_embeds  # Image features\n",
    "    return meme_image_features\n",
    "\n",
    "# Function to query memes based on text similarity\n",
    "def query_memes_by_text(query_text, meme_folder, top_n=5, similarity_weight=0.5):\n",
    "    # Extract features for the query text\n",
    "    query_text_features = extract_text_features(query_text)\n",
    "    \n",
    "    # Initialize a list to store meme image features\n",
    "    image_features = []\n",
    "    meme_files = []\n",
    "\n",
    "    # Loop through all meme images in the folder and extract their features using the query text\n",
    "    for filename in os.listdir(meme_folder):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.webp')):\n",
    "            meme_path = os.path.join(meme_folder, filename)\n",
    "            meme_image = Image.open(meme_path)  # Open the image file using PIL\n",
    "            \n",
    "            # Extract image features for the meme\n",
    "            meme_image_features = extract_image_features(meme_image, query_text)\n",
    "            image_features.append(meme_image_features)\n",
    "            meme_files.append(filename)\n",
    "\n",
    "    # Convert list of image features to a tensor\n",
    "    image_features = torch.stack(image_features).squeeze(1)\n",
    "\n",
    "    # Step 1: Calculate cosine similarity between the query text and meme image features\n",
    "    text_similarities = cosine_similarity(query_text_features.detach().numpy(), image_features.detach().numpy()).flatten()\n",
    "\n",
    "    # Step 2: Calculate cosine similarity between the query image and meme image features\n",
    "    image_similarities = cosine_similarity(query_text_features.detach().numpy(), image_features.detach().numpy()).flatten()\n",
    "\n",
    "    # Combine text and image similarities using weighted sum\n",
    "    combined_similarities = (similarity_weight * text_similarities + (1 - similarity_weight) * image_similarities)\n",
    "\n",
    "    # Step 3: Get the top N memes based on combined similarity\n",
    "    top_indices = combined_similarities.argsort()[-top_n:][::-1]  # Indices of top N matches\n",
    "    top_memes = [(meme_files[i], combined_similarities[i]) for i in top_indices]\n",
    "\n",
    "    return top_memes\n",
    "\n",
    "# Example usage\n",
    "query_text = \"Cat\"  # Example query text\n",
    "meme_folder = \"C:/Users/mahed/OneDrive/Desktop/The Meme Files-20241214T145346Z-001/The Meme Files\"  # Path to the folder containing meme images\n",
    "\n",
    "# Get top matching memes based on text similarity\n",
    "image_results = query_memes_by_text(query_text, meme_folder)\n",
    "\n",
    "# Print the top memes based on the query text\n",
    "print(\"Top memes based on text query:\")\n",
    "for image, score in image_results:\n",
    "    print(f\"Image: {image}, Similarity: {score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv-GPU)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
